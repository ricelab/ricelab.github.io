---
layout: default-project
title: "Remote Embodiment for Shared Activity"
subtitle: Allowing others to see and understand us

categories:
    - projects

thumbnail: /assets/images/onespace-thumbnail.jpg
permalink: "/projects/remote-embodiment/"
---
{% include figure.html src="/assets/images/project-images/threes-company.jpg" caption='Three remote spaces are connected such that each collaborator is represented through video and audio connections, as well as arm-embodiments on the work surface.' %}

When we interact with others at a distance, we are often limited to a shared artefact (e.g. a document). We can augment this using Skype, adding both voice and audio, though frequently, this is not enough -- it is easy to misunderstand what someone is saying, or lose sight of what the other person is doing with respect to that document. What is missing is an _embodiment_ of the remote collaborator -- that is, we cannot see their bodies, and those bodies' relationship with the shared artefact or space. In this project, we are exploring how different ways of embodying remote participants can help support effective interaction.


{% include figure.html src="/assets/images/project-images/video-arms.jpg" caption='With VideoArms, collaborators are represented in remote workspaces via a video-captured arm.' %}

**VideoArms.** Many of our explorations focus on embodying a remote participants' arms and hands in a shared visual workspace (e.g. {% cite genest2013kinectarms yarosh2013almost tang2010threes tang2010expressiveness tang2007videoarms tang2005understanding tang2005awarenessmpg tang2004videoarms %}). Arms are important as they provide a rich means of expressing intent -- both intentionally (e.g. when we explicitly point at things), and unintentionally (e.g. when we are simply working, our arms touch the things we care about). We have designed new ways of capturing and visualizing different characteristics of these arms (e.g. using the Kinect to capture height information {% cite genest2013kinectarms %}), and demonstrated that they can be effective in three-way interaction {% cite tang2010threes %}. We have also explored how the fidelity of the representation can be used for expressive purposes {% cite tang2010expressiveness %}.


{% include figure.html src="/assets/images/project-images/onespace.jpg" caption='In OneSpace, people from remote spaces are combined into a shared visual environment.' %}


**Children and Video.** In designing systems for supporting interaction between children, we have found that simply showing video of a person's head (for example, through Skype) is frequently not enough. Instead, it is useful to scaffold the interaction, for instance by focusing on interaction with a tabletop {% cite yarosh2013sharetablevideo yarosh2013almost %}, or by allowing for full-body play and interaction with digital objects {% cite cohen2014onespace hunter2014waazaam %}.



{% include figure.html src="/assets/images/project-images/art-therapy.jpg" caption='This prototype illustrates a drawing space where people are represented by stick figures to preserve anonymity.' %}

**Bodily Representation.** We have designed several systems to explore how full-body representation can be used for various applications. With OneSpace {% cite ledo2013onespace cohen2014onespace dillman2013remotephysiotherapy ledo2013onespaceworkshop ledo2012onespace %}, we explored high-fidelity video representation, and how that impacts interaction. In a separate project involving art therapy, we explored the use of simple stickman representations to protect the identity of participants {% cite jones2014arttherapy %}. We have also been exploring a complete absence of visual representation, exploring the possibility of using vibrotactile, haptic representation {% cite alizadeh2014haptics %}


## Publications

{% bibliography --cited %}

