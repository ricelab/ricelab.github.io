<!DOCTYPE HTML>
<!--
	Arcana by HTML5 UP - html5up.net 
-->
<html>
	<head>
		<title>Prompting an Embodied AI Agent: How Embodiment and Multimodal Signaling Affects Prompting Behaviour</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<!--[if lte IE 8]><script src="/assets/css/ie/html5shiv.js"></script><![endif]-->
		<script src="/assets/js/jquery.min.js"></script>
		<script src="/assets/js/jquery.dropotron.min.js"></script>
		<script src="/assets/js/skel.min.js"></script>
		<script src="/assets/js/skel-layers.min.js"></script>
		<script src="/assets/js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="/assets/css/skel.css" />
			<link rel="stylesheet" href="/assets/css/style.css" />
			<link rel="stylesheet" href="/assets/css/style-wide.css" />
		</noscript>
		<!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie/v8.css" /><![endif]-->
		<link rel="shortcut icon" href="/assets/images/favicon.png">
		
	</head>
	<body>

		<!-- Header -->
			<div id="header">
						
				<!-- Logo -->
					<h1><a href="/index.html" id="logo">RICELab <em style="font-size: 9pt;color: #cbcbcb" class="only-large">Rethinking Interaction Collaboration and Engagement</em></a></h1>
				
				<!-- Nav -->
					<nav id="nav">
						<ul>
							
							<li ><a href="/index.html">Home</a></li>
							<li ><a href="/about-us">About Us</a></li>
							<li ><a href="/people">People</a></li>
							<li ><a href="/projects">Projects</a></li>
							<li class="current"><a href="/papers">Publications</a></li>
							<li ><a href="/blog">Blog</a></li>
							<li ><a href="/join-us">Join Us</a></li>
							<li ><a href="/internal">Internal</a></li>
						</ul>
					</nav>
			</div>
<style>
#citation a {
  color: black;
  border-bottom: none;
}
#citation {
  margin-bottom: 1em;
}
</style>

	<!-- Main -->
	<section class="wrapper style1">
		<div class="container">
			<div class="row double">
				<div class="3u">
					<div id="sidebar">
	<!-- Sidebar -->
	<section>
		<h3>See publications</h3>
		<ul>
			<li><a href="/papers/">by Year</a></li>
			<li><a href="/papers/byType.html">by Publication Type</a></li>
		</ul>
		
	</section>
</div>
				</div>
				<div class="9u skel-cell-important">
					<div id="content">
						<!-- Content -->
						<h1 style="margin: 0 0 0.5em 0">Prompting an Embodied AI Agent: How Embodiment and Multimodal Signaling Affects Prompting Behaviour</h1>

<p style="margin: 0.5em 0 1em 0">
<span id="zhang2025embodiedagent">Tianyi Zhang, Colin Au Yeung, Emily Aurelia, Yuki Onishi, Neil Chulpongsatorn, Jiannan Li, and Anthony Tang. (2025). <span style="text-decoration: underline">Prompting an Embodied AI Agent: How Embodiment and Multimodal Signaling Affects Prompting Behaviour</span>. In <i>Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems</i>, Association for Computing Machinery.</span>


	<small>Notes: Honourable Mention Award (Top 5% of all submissions).</small>


</p>

<h2>Abstract</h2>
<p style="margin: 0.5em 0 1em 0">Current voice agents wait for a user to complete their verbal instruction before responding; yet, this is misaligned with how humans engage in everyday conversational interaction, where interlocutors use multimodal signaling (e.g. nodding, grunting, or looking at referred to objects) to ensure conversational grounding. We designed an embodied VR agent that exhibits multimodal signaling behaviors in response to situated prompts, by turning its head, or by visually highlighting objects being discussed or referred to. We explore how people prompt this agent to design and manipulate the objects in a VR scene. Through a Wizard of Oz study, we found that participants interacting with an agent that indicated its understanding of spatial and action references were able to prevent errors 30% of the time, and were more satisfied and confident in the agentâ€™s abilities. These findings underscore the importance of designing multimodal signaling communication techniques for future embodied agents.</p>

<!--

-->

<h2>Materials</h2>
<p style="margin: 0.5em 0 1em 0">


	<a href="https://doi.org/10.1145/3706598.3713110"><i class="fa fa-sticky-note-o"></i> URL (https://doi.org/10.1145/3706598.3713110)</a><br/>



	<a href="10.1145/3706598.3713110"><i class="fa fa-external-link"></i> DOI (10.1145/3706598.3713110)</a><br/>

</p>


<h2>Keywords</h2>
<p style="margin: 0.5em 0 1em 0">situated prompting, multimodal signaling, common ground, human-ai collaboration</p>


<h2>BibTeX</h2>
<p style="font-family: 'Lucida Sans Typewriter', 'Lucida Console', Monaco, 'Bitstream Vera Sans Mono', monospace; font-size: small; background-color: rgb(240,240,240); border: 2px solid; border-color: rgb(222,222,222); border-radius: 5px; margin: 0.5em 0 0 0; line-height: 1em; letter-spacing: 0em">@inproceedings{zhang2025embodiedagent,<br />
&nbsp;&nbsp;author = {Zhang, Tianyi and Au Yeung, Colin and Aurelia, Emily and Onishi, Yuki and Chulpongsatorn, Neil and Li, Jiannan and Tang, Anthony},<br />
&nbsp;&nbsp;title = {Prompting an Embodied AI Agent: How Embodiment and Multimodal Signaling Affects Prompting Behaviour},<br />
&nbsp;&nbsp;year = {2025},<br />
&nbsp;&nbsp;publisher = {Association for Computing Machinery},<br />
&nbsp;&nbsp;url = {https://doi.org/10.1145/3706598.3713110},<br />
&nbsp;&nbsp;doi = {10.1145/3706598.3713110},<br />
&nbsp;&nbsp;booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},<br />
&nbsp;&nbsp;articleno = {60},<br />
&nbsp;&nbsp;numpages = {25},<br />
&nbsp;&nbsp;keywords = {situated prompting, multimodal signaling, common ground, human-ai collaboration},<br />
&nbsp;&nbsp;series = {CHI '25},<br />
&nbsp;&nbsp;type = {conference},<br />
&nbsp;&nbsp;notes = {Honourable Mention Award (Top 5% of all submissions)}<br />
}<br />
</p>
					</div>
				</div>
			</div>
		</div>
	</section>			

		<!-- Footer -->
 			<div id="footer">
				<!-- Copyright -->
					<div class="copyright">
					    <script type="text/javascript">
					    // from http://grouplab.cpsc.ucalgary.ca/
					    function hideshow(el){
						    if (!document.getElementById) return;
						    if (el.style.visibility=="visible") {
						    	el.style.visibility="hidden"
						    }
						    else {
						    	el.style.visibility="visible"
						    }
						}
					    </script>
						<ul class="menu">
							<!--
							<li><a href="https://www.google.ca/maps/place/Math+Science,+Calgary,+AB+T2N+4V8/@51.0799635,-114.1300982,17z/data=!3m1!4b1!4m2!3m1!1s0x53716f0c07993c17:0xb8f1352e9e5dfa06?hl=en"><i class="icon fa-map-marker"></i> 2500 University Drive NW, Calgary, AB T2N 1N4</a> (<a href="/directions">Directions</a>)</li><li><a href="tel:403-210-6912"><i class="icon fa-phone"></i> 403-210-6912</a></li>
							-->
							<li><a rel="nofollow" href="javascript:hideshow(document.getElementById('colophon'))">Colophon</a></li>
						</ul>
						<section id="colophon" visibility="hidden" style="visibility: hidden;">
							<ul class="menu">
								<li>Design: <a href="http://html5up.net">HTML5 UP</a></li><li>Images: <a href="http://unsplash.com/">unsplash.com</a></li><li>Icons: <a href="https://fortawesome.github.io/Font-Awesome/">font awesome</a></li><li>Bibliography: <a href="https://github.com/inukshuk/jekyll-scholar">jekyll-scholar</a></li>
							</ul>
						</section>
					</div>

			</div>

	</body>
</html>