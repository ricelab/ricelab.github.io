<!DOCTYPE HTML>
<!--
	Arcana by HTML5 UP - html5up.net 
-->
<html>
	<head>
		<title>Haptics in VR</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<!--[if lte IE 8]><script src="/assets/css/ie/html5shiv.js"></script><![endif]-->
		<script src="/assets/js/jquery.min.js"></script>
		<script src="/assets/js/jquery.dropotron.min.js"></script>
		<script src="/assets/js/skel.min.js"></script>
		<script src="/assets/js/skel-layers.min.js"></script>
		<script src="/assets/js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="/assets/css/skel.css" />
			<link rel="stylesheet" href="/assets/css/style.css" />
			<link rel="stylesheet" href="/assets/css/style-wide.css" />
		</noscript>
		<!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie/v8.css" /><![endif]-->
		<link rel="shortcut icon" href="/assets/images/favicon.png">
		
	</head>
	<body>

		<!-- Header -->
			<div id="header">
						
				<!-- Logo -->
					<h1><a href="/index.html" id="logo">RICELab <em style="font-size: 9pt;color: #cbcbcb" class="only-large">Rethinking Interaction Collaboration and Engagement</em></a></h1>
				
				<!-- Nav -->
					<nav id="nav">
						<ul>
							
							<li ><a href="/index.html">Home</a></li>
							<li ><a href="/about-us">About Us</a></li>
							<li ><a href="/people">People</a></li>
							<li class="current"><a href="/projects">Projects</a></li>
							<li ><a href="/papers">Publications</a></li>
							<li ><a href="/blog">Blog</a></li>
							<li ><a href="/join-us">Join Us</a></li>
							<li ><a href="/internal">Internal</a></li>
						</ul>
					</nav>
			</div>
<style>
#citation a {
  color: black;
  border-bottom: none;
}
#citation {
  margin-bottom: 1em;
}
</style>

<!-- Main -->
	<section class="wrapper style1">
		<div class="container">
			<div class="row double">
				<div class="4u">
					<div id="sidebar">

	<!-- Sidebar -->

		<section>
			<h3>Current Projects</h3>
			<ul>
			  
			    
			      <li><a href="/projects/hai-collaboration/">Human-AI Collaboration</a></li>
			    
			  
			    
			      <li><a href="/projects/proxemics/">Proxemic Interaction Design</a></li>
			    
			  
			    
			      <li><a href="/projects/haptics/">Haptics in VR</a></li>
			    
			  
			    
			      <li><a href="/projects/games/">Games and Leisure</a></li>
			    
			  
			    
			      <li><a href="/projects/efashion/">Electronic Fashion</a></li>
			    
			  
			    
			      <li><a href="/projects/360video/">360 Video Interaction</a></li>
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			</ul>

			<h3>Past Projects</h3>
			<ul>
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			      <li><a href="/projects/teaching-technologies/">Technologies for Teaching</a></li>
			    
			  
			    
			      <li><a href="/projects/social-watching-of-sports/">Social Watching of Sports</a></li>
			    
			  
			    
			      <li><a href="/projects/slit-tear-video/">Slit-Tear Video Exploration</a></li>
			    
			  
			    
			      <li><a href="/projects/remote-embodiment/">Remote Embodiment for Shared Activity</a></li>
			    
			  
			    
			      <li><a href="/projects/personal-informatics/">Personal Informatics and Analytics</a></li>
			    
			  
			    
			      <li><a href="/projects/physiotherapy/">Physiotherapy for the Future</a></li>
			    
			  
			    
			      <li><a href="/projects/pervasive-games/">Pervasive Games and Citizen Science</a></li>
			    
			  
			    
			      <li><a href="/projects/mobile-video-conferencing/">Mobile Video Conferencing</a></li>
			    
			  
			    
			      <li><a href="/projects/mobile-device-interaction/">Interaction Techniques for Mobile Devices</a></li>
			    
			  
			    
			      <li><a href="/projects/mixed-reality-workrooms/">Mixed Reality Workrooms</a></li>
			    
			  
			    
			      <li><a href="/projects/collaborative-visual-analytics/">Collaborative Visual Analytics</a></li>
			    
			  
			    
			      <li><a href="/projects/collaborative-ar/">Mixed Reality for Collaboration</a></li>
			    
			  
			    
			      <li><a href="/projects/multi-surface-environments/">Digital Workrooms of the Future</a></li>
			    
			  
			</ul>
		</section>
</div>
				</div>
				<div class="8u skel-cell-important">
					<div id="content">

						<!-- Content -->
					
							<article>
								<header>
									<h2>Haptics in VR</h2>
									<p>Enhancing VR experiences with haptics and haptic illusions</p>
								</header>
								
								<!-- 160x144 -->

<p>Virtual Reality experiences typically focus on the visual aspects of immersion. This project has explored the challenges of creating haptic experiences for such immersive experiences – first through the use of tangible devices, and then through the use of visio-haptic illusions.</p>

<p>One way to create haptic experiences is through the use of tangible devices – that is, things that you can physically hold and feel. Yet, the challenge with this is that we may have fantastical items in VR that are difficult to re-create in real life. To this end, we developed the Tangi toolkit <a class="citation" href="#feick2020tangi">(Feick, Bateman, Tang, Miede, &amp; Marquardt, 2020)</a>, which provided a means for designers to create physical objects that approximate what we see in the VR space. To some extent, these devices also had the capacity to be moved, and this added an element of additional realism.</p>

<p>The experience with Tangi made us realize that we were relying on a type of visuo-haptic illusion – that is, the idea that the visual aspects of the experience override our experience of the haptic sensation. This allowed us, for instance, to use blocky building blocks to represent what would otherwise be a smoothly-shaped bunny rabbit. To this end, we wanted to explore the limits of these illusions: to what extent can you approximate the physical/motor aspects of interacting with these objects without creating a “break” in the illusion? We explored these with linear physical proxies <a class="citation" href="#feick2021illusions">(Feick, Kleer, Zenner, Tang, &amp; Krüger, 2021)</a>, and then later more generally with multiple variables at play <a class="citation" href="#feick2022illusions">(Feick, Regitz, Tang, &amp; Krüger, 2022)</a>.</p>

<p>The work has resulted in interesting side projects with the idea of drones creating these illusions <a class="citation" href="#feick2022hapticpuppet">(Feick, Tang, &amp; Krug̈er, 2022)</a>, as well as toolkits for measuring immersion within VR <a class="citation" href="#feick2020vrqt">(Feick, Kleer, Tang, &amp; Krüger, 2020)</a>. Further, we have now begun exploring physiological metrics to determine when the illusion breaks <a class="citation" href="#feick2023handredirection">(Feick, Regitz, Tang, Jungbluth, Rekrut, &amp; Krüger, 2023)</a>, which should allow us to one day create rich experiences without subjective reports on immersion.</p>

<h2 id="publications">Publications</h2>

<ol class="bibliography"><li><section id="citation">
    <a href="/papers/feick2023handredirection"><span id="feick2023handredirection">Martin Feick, Kora Persephone Regitz, Anthony Tang, Tobias Jungbluth, Maurice Rekrut, and Antonio Krüger. (2023). <span style="text-decoration: underline">Investigating Noticeable Hand Redirection in Virtual Reality using Physiological and Interaction Data</span>. In <i>IEEE VR ’23: IEEE Conference on Virtual Reality and 3D User Interfaces</i>.</span>

(conference).</a><br />




	<a href="http://hcitang.org/papers/2023-vr2023-feick-handredirection.pdf"><i class="fa fa-file-pdf-o"></i></a>



	<a href="https://www.youtube.com/watch?v=HBqPnrxU0ek"><i class="fa fa-film"></i></a>


	<a href="https://doi.org/10.1109/VR55154.2023.00035"><i class="fa fa-external-link"></i></a>

</section><a class="details" href="/papers/feick2023handredirection/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/feick2022hapticpuppet"><span id="feick2022hapticpuppet">Martin Feick, Anthony Tang, and Krug̈er. (2022). <span style="text-decoration: underline"> HapticPuppet: A Kinesthetic Mid-air Multidirectional Force-Feedback Drone-based Interface </span>. In <i>UIST ’22: The Adjunct Publication of the 35th Annual ACM Symposium on User Interface Software and Technology</i>.</span>

(poster).</a><br />




	<a href=" http://hcitang.org/papers/2022-uist2022poster-feick-hapticpuppet.pdf"><i class="fa fa-file-pdf-o"></i></a>



	<a href=" http://hcitang.org/papers/2022-uist2022poster-feick-hapticpuppet.mp4"><i class="fa fa-film"></i></a>


	<a href="https://doi.org/10.1145/3526114.3558694"><i class="fa fa-external-link"></i></a>

</section><a class="details" href="/papers/feick2022hapticpuppet/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/feick2022illusions"><span id="feick2022illusions">Martin Feick, Kora Persephone Regitz, Anthony Tang, and Antonio Krüger. (2022). <span style="text-decoration: underline">Designing Visuo-Haptic Illusions with Proxies in Virtual Reality: Exploration of Grasp, Movement Trajectory and Object Mass</span>. In <i>CHI 2022: Proceedings of the 2022 SIGCHI Conference on Human Factors in Computing Systems</i>.</span>

(conference).</a><br />

	<small>Acceptance: 24.7% - 638/2579.</small>



	<br />


	<a href="http://hcitang.org/papers/2022-chi2022-feick-illusions.pdf"><i class="fa fa-file-pdf-o"></i></a>


	<a href="http://hcitang.org/papers/2022-chi2022-feick-illusions-talk.mp4"><i class="fa fa-sticky-note-o"></i></a>


	<a href="http://hcitang.org/papers/2022-chi2022-feick-illusions.mp4"><i class="fa fa-film"></i></a>


	<a href="https://doi.org/10.1145/3491102.3517671"><i class="fa fa-external-link"></i></a>

</section><a class="details" href="/papers/feick2022illusions/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/feick2021illusions"><span id="feick2021illusions">Martin Feick, Niko Kleer, André Zenner, Anthony Tang, and Antonio Krüger. (2021). <span style="text-decoration: underline">Visuo-haptic Illusions for Linear Translation and Stretching using Physical Proxies in Virtual Reality</span>. In <i>CHI 2021: Proceedings of the 2021 SIGCHI Conference on Human Factors in Computing Systems</i>.</span>

(conference).</a><br />

	<small>Acceptance: 26.3% - 749/2844.</small>



	<br />


	<a href="http://hcitang.org/papers/2021-chi2021-feick-visio-haptic-illusions.pdf"><i class="fa fa-file-pdf-o"></i></a>



	<a href="http://hcitang.org/papers/2021-chi2021-feick-visio-haptic-illusions.mp4"><i class="fa fa-film"></i></a>


	<a href="https://doi.org/10.1145/3411764.3445456"><i class="fa fa-external-link"></i></a>

</section><a class="details" href="/papers/feick2021illusions/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/feick2020vrqt"><span id="feick2020vrqt">Martin Feick, Niko Kleer, Anthony Tang, and Antonio Krüger. (2020). <span style="text-decoration: underline">The Virtual Reality Questionnaire Toolkit</span>. In <i>AP UIST 2020: Adjunct Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, UIST 2019</i>.</span>

(poster).</a><br />




	<a href="http://hcitang.org/papers/2020-uist2020wip-feick-vrqt.pdf"><i class="fa fa-file-pdf-o"></i></a>


	<a href="https://github.com/MartinFk/VRQuestionnaireToolkit"><i class="fa fa-sticky-note-o"></i></a>



</section><a class="details" href="/papers/feick2020vrqt/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/feick2020tangi"><span id="feick2020tangi">Martin Feick, Scott Bateman, Anthony Tang, André Miede, and Nicolai Marquardt. (2020). <span style="text-decoration: underline">TanGi: Tangible Proxies for Embodied Object Exploration and Manipulation in Virtual Reality</span>. In <i>ISMAR 2020: 2020 IEEE International Symposium on Mixed and Augmented Reality</i>.</span>

(conference).</a><br />

	<small>Acceptance: 28.8% - 87/302.</small>



	<br />


	<a href="http://hcitang.org/papers/2020-ismar2020-feick-tangi.pdf"><i class="fa fa-file-pdf-o"></i></a>



	<a href="http://hcitang.org/papers/2020-ismar2020-feick-tangi.mp4"><i class="fa fa-film"></i></a>


</section><a class="details" href="/papers/feick2020tangi/"><!-- --></a></li></ol>



							</article>
					</div>
				</div>
			</div>
		</div>
	</section>			

		<!-- Footer -->
 			<div id="footer">
				<!-- Copyright -->
					<div class="copyright">
					    <script type="text/javascript">
					    // from http://grouplab.cpsc.ucalgary.ca/
					    function hideshow(el){
						    if (!document.getElementById) return;
						    if (el.style.visibility=="visible") {
						    	el.style.visibility="hidden"
						    }
						    else {
						    	el.style.visibility="visible"
						    }
						}
					    </script>
						<ul class="menu">
							<!--
							<li><a href="https://www.google.ca/maps/place/Math+Science,+Calgary,+AB+T2N+4V8/@51.0799635,-114.1300982,17z/data=!3m1!4b1!4m2!3m1!1s0x53716f0c07993c17:0xb8f1352e9e5dfa06?hl=en"><i class="icon fa-map-marker"></i> 2500 University Drive NW, Calgary, AB T2N 1N4</a> (<a href="/directions">Directions</a>)</li><li><a href="tel:403-210-6912"><i class="icon fa-phone"></i> 403-210-6912</a></li>
							-->
							<li><a rel="nofollow" href="javascript:hideshow(document.getElementById('colophon'))">Colophon</a></li>
						</ul>
						<section id="colophon" visibility="hidden" style="visibility: hidden;">
							<ul class="menu">
								<li>Design: <a href="http://html5up.net">HTML5 UP</a></li><li>Images: <a href="http://unsplash.com/">unsplash.com</a></li><li>Icons: <a href="https://fortawesome.github.io/Font-Awesome/">font awesome</a></li><li>Bibliography: <a href="https://github.com/inukshuk/jekyll-scholar">jekyll-scholar</a></li>
							</ul>
						</section>
					</div>

			</div>

	</body>
</html>