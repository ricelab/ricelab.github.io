<!DOCTYPE HTML>
<!--
	Arcana by HTML5 UP - html5up.net 
-->
<html>
	<head>
		<title>Remote Embodiment for Shared Activity</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<!--[if lte IE 8]><script src="/assets/css/ie/html5shiv.js"></script><![endif]-->
		<script src="/assets/js/jquery.min.js"></script>
		<script src="/assets/js/jquery.dropotron.min.js"></script>
		<script src="/assets/js/skel.min.js"></script>
		<script src="/assets/js/skel-layers.min.js"></script>
		<script src="/assets/js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="/assets/css/skel.css" />
			<link rel="stylesheet" href="/assets/css/style.css" />
			<link rel="stylesheet" href="/assets/css/style-wide.css" />
		</noscript>
		<!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie/v8.css" /><![endif]-->
		<link rel="shortcut icon" href="/assets/images/favicon.png">
		
	</head>
	<body>

		<!-- Header -->
			<div id="header">
						
				<!-- Logo -->
					<h1><a href="/index.html" id="logo">RICELab <em style="font-size: 9pt;color: #cbcbcb" class="only-large">Rethinking Interaction Collaboration and Engagement</em></a></h1>
				
				<!-- Nav -->
					<nav id="nav">
						<ul>
							
							<li ><a href="/index.html">Home</a></li>
							<li ><a href="/about-us">About Us</a></li>
							<li ><a href="/people">People</a></li>
							<li class="current"><a href="/projects">Projects</a></li>
							<li ><a href="/papers">Publications</a></li>
							<li ><a href="/blog">Blog</a></li>
							<li ><a href="/join-us">Join Us</a></li>
							<li ><a href="/internal">Internal</a></li>
						</ul>
					</nav>
			</div>
<style>
#citation a {
  color: black;
  border-bottom: none;
}
#citation {
  margin-bottom: 1em;
}
</style>

<!-- Main -->
	<section class="wrapper style1">
		<div class="container">
			<div class="row double">
				<div class="4u">
					<div id="sidebar">

	<!-- Sidebar -->

		<section>
			<h3>Current Projects</h3>
			<ul>
			  
			    
			      <li><a href="/projects/hai-collaboration/">Human-AI Collaboration</a></li>
			    
			  
			    
			      <li><a href="/projects/proxemics/">Proxemic Interaction Design</a></li>
			    
			  
			    
			      <li><a href="/projects/haptics/">Haptics in VR</a></li>
			    
			  
			    
			      <li><a href="/projects/games/">Games and Leisure</a></li>
			    
			  
			    
			      <li><a href="/projects/efashion/">Electronic Fashion</a></li>
			    
			  
			    
			      <li><a href="/projects/360video/">360 Video Interaction</a></li>
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			</ul>

			<h3>Past Projects</h3>
			<ul>
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			      <li><a href="/projects/teaching-technologies/">Technologies for Teaching</a></li>
			    
			  
			    
			      <li><a href="/projects/social-watching-of-sports/">Social Watching of Sports</a></li>
			    
			  
			    
			      <li><a href="/projects/slit-tear-video/">Slit-Tear Video Exploration</a></li>
			    
			  
			    
			      <li><a href="/projects/remote-embodiment/">Remote Embodiment for Shared Activity</a></li>
			    
			  
			    
			      <li><a href="/projects/personal-informatics/">Personal Informatics and Analytics</a></li>
			    
			  
			    
			      <li><a href="/projects/physiotherapy/">Physiotherapy for the Future</a></li>
			    
			  
			    
			      <li><a href="/projects/pervasive-games/">Pervasive Games and Citizen Science</a></li>
			    
			  
			    
			      <li><a href="/projects/mobile-video-conferencing/">Mobile Video Conferencing</a></li>
			    
			  
			    
			      <li><a href="/projects/mobile-device-interaction/">Interaction Techniques for Mobile Devices</a></li>
			    
			  
			    
			      <li><a href="/projects/mixed-reality-workrooms/">Mixed Reality Workrooms</a></li>
			    
			  
			    
			      <li><a href="/projects/collaborative-visual-analytics/">Collaborative Visual Analytics</a></li>
			    
			  
			    
			      <li><a href="/projects/collaborative-ar/">Mixed Reality for Collaboration</a></li>
			    
			  
			    
			      <li><a href="/projects/multi-surface-environments/">Digital Workrooms of the Future</a></li>
			    
			  
			</ul>
		</section>
</div>
				</div>
				<div class="8u skel-cell-important">
					<div id="content">

						<!-- Content -->
					
							<article>
								<header>
									<h2>Remote Embodiment for Shared Activity</h2>
									<p>Allowing others to see and understand us</p>
								</header>
								
								
<figure>

	<img src="/assets/images/project-images/threes-company.jpg" alt="Three remote spaces are connected such that each collaborator is represented through video and audio connections, as well as arm-embodiments on the work surface." width="100%" />


<figcaption>
    Three remote spaces are connected such that each collaborator is represented through video and audio connections, as well as arm-embodiments on the work surface.
</figcaption>

</figure>

<p>When we interact with others at a distance, we are often limited to a shared artefact (e.g. a document). We can augment this using Skype, adding both voice and audio, though frequently, this is not enough – it is easy to misunderstand what someone is saying, or lose sight of what the other person is doing with respect to that document. What is missing is an <em>embodiment</em> of the remote collaborator – that is, we cannot see their bodies, and those bodies’ relationship with the shared artefact or space. In this project, we are exploring how different ways of embodying remote participants can help support effective interaction.</p>

<figure>

	<img src="/assets/images/project-images/video-arms.jpg" alt="With VideoArms, collaborators are represented in remote workspaces via a video-captured arm." width="100%" />


<figcaption>
    With VideoArms, collaborators are represented in remote workspaces via a video-captured arm.
</figcaption>

</figure>

<p><strong>VideoArms.</strong> Many of our explorations focus on embodying a remote participants’ arms and hands in a shared visual workspace (e.g. <a class="citation" href="#genest2013kinectarms">(Genest, Gutwin, Tang, Kalyn, &amp; Ivkovic, 2013; Yarosh, Tang, Mokashi, &amp; Abowd, 2013; Tang, Pahud, Inkpen, Benko, Tang, &amp; Buxton, 2010; Tang, Genest, Shoemaker, Gutwin, Fels, &amp; Booth, 2010; Tang, Neustaedter, &amp; Greenberg, 2007; Tang, Boyle, &amp; Greenberg, 2005; Tang &amp; Greenberg, 2005; Tang, Neustaedter, &amp; Greenberg, 2004)</a>). Arms are important as they provide a rich means of expressing intent – both intentionally (e.g. when we explicitly point at things), and unintentionally (e.g. when we are simply working, our arms touch the things we care about). We have designed new ways of capturing and visualizing different characteristics of these arms (e.g. using the Kinect to capture height information <a class="citation" href="#genest2013kinectarms">(Genest, Gutwin, Tang, Kalyn, &amp; Ivkovic, 2013)</a>), and demonstrated that they can be effective in three-way interaction <a class="citation" href="#tang2010threes">(Tang, Pahud, Inkpen, Benko, Tang, &amp; Buxton, 2010)</a>. We have also explored how the fidelity of the representation can be used for expressive purposes <a class="citation" href="#tang2010expressiveness">(Tang, Genest, Shoemaker, Gutwin, Fels, &amp; Booth, 2010)</a>.</p>

<figure>

	<img src="/assets/images/project-images/onespace.jpg" alt="In OneSpace, people from remote spaces are combined into a shared visual environment." width="100%" />


<figcaption>
    In OneSpace, people from remote spaces are combined into a shared visual environment.
</figcaption>

</figure>

<p><strong>Children and Video.</strong> In designing systems for supporting interaction between children, we have found that simply showing video of a person’s head (for example, through Skype) is frequently not enough. Instead, it is useful to scaffold the interaction, for instance by focusing on interaction with a tabletop <a class="citation" href="#yarosh2013sharetablevideo">(Yarosh, Tang, Mokashi, &amp; Abowd, 2013; Yarosh, Tang, Mokashi, &amp; Abowd, 2013)</a>, or by allowing for full-body play and interaction with digital objects <a class="citation" href="#cohen2014onespace">(Cohen, Dillman, MacLeod, Hunter, &amp; Tang, 2014; Hunter, Maes, Tang, &amp; Inkpen, 2014)</a>.</p>

<figure>

	<img src="/assets/images/project-images/art-therapy.jpg" alt="This prototype illustrates a drawing space where people are represented by stick figures to preserve anonymity." width="100%" />


<figcaption>
    This prototype illustrates a drawing space where people are represented by stick figures to preserve anonymity.
</figcaption>

</figure>

<p><strong>Bodily Representation.</strong> We have designed several systems to explore how full-body representation can be used for various applications. With OneSpace <a class="citation" href="#ledo2013onespace">(Ledo, Aseniero, Greenberg, Boring, &amp; Tang, 2013; Cohen, Dillman, MacLeod, Hunter, &amp; Tang, 2014; Dillman &amp; Tang, 2013; Ledo, Aseniero, Boring, Greenberg, &amp; Tang, 2013; Ledo, Aseniero, Boring, &amp; Tang, 2012)</a>, we explored high-fidelity video representation, and how that impacts interaction. In a separate project involving art therapy, we explored the use of simple stickman representations to protect the identity of participants <a class="citation" href="#jones2014arttherapy">(Jones, Hankinson, Collie, &amp; Tang, 2014)</a>. We have also been exploring a complete absence of visual representation, exploring the possibility of using vibrotactile, haptic representation <a class="citation" href="#alizadeh2014haptics">(Alizadeh, Tang, Sharlin, &amp; Tang, 2014)</a></p>

<h2 id="publications">Publications</h2>

<ol class="bibliography"><li><section id="citation">
    <a href="/papers/hunter2014waazaam"><span id="hunter2014waazaam">Seth Hunter, Pattie Maes, Anthony Tang, and Kori Inkpen. (2014). <span style="text-decoration: underline">WaaZaam! Supporting Creative Play at a Distance in Customized Video Environments</span>. In <i>CHI ’14 Proceedings of the SIGCHI Conference on Human Factors in Computing
    Systems</i>, ACM, 1197–1206.</span>

(conference).</a><br />

	<small>Acceptance: 22.8% - 471/2064.</small>


	<small>Notes: Honourable Mention - Top 5% of all submissions.</small>


	<br />


	<a href="http://hcitang.org/papers/2014-chi2014-waazam.pdf"><i class="fa fa-file-pdf-o"></i></a>




	<a href="http://dx.doi.org/10.1145/2556288.2557382"><i class="fa fa-external-link"></i></a>

</section><a class="details" href="/papers/hunter2014waazaam/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/cohen2014onespace"><span id="cohen2014onespace">Maayan Cohen, Kody Dillman, Haley MacLeod, Seth Hunter, and Anthony Tang. (2014). <span style="text-decoration: underline">OneSpace: Shared Visual Scenes for Active Freeplay</span>. In <i>CHI ’14 Proceedings of the SIGCHI Conference on Human Factors in Computing
    Systems</i>, ACM, 2177–2180.</span>

(conference).</a><br />

	<small>Acceptance: 22.8% - 471/2064.</small>


	<small>Notes: Honourable Mention - Top 5% of all submissions.</small>


	<br />


	<a href="http://hcitang.org/papers/2014-chi2014-freeplay.pdf"><i class="fa fa-file-pdf-o"></i></a>



	<a href="http://hcitang.org/papers/2014-chi2014-freeplay-in-onespace.mov"><i class="fa fa-film"></i></a>


	<a href="http://dx.doi.org/10.1145/2556288.2557117"><i class="fa fa-external-link"></i></a>

</section><a class="details" href="/papers/cohen2014onespace/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/alizadeh2014haptics"><span id="alizadeh2014haptics">Hesam Alizadeh, Richard Tang, Ehud Sharlin, and Anthony Tang. (2014). <span style="text-decoration: underline">Haptics in Remote Collaborative Exercise Systems for Seniors</span>. In <i>CHI EA ’14: CHI ’14 Extended Abstracts on Human Factors in Computing
    Systems</i>, ACM, 2401–2406.</span>

(poster).</a><br />

	<small>Acceptance: 49% - 241/496.</small>


	<small>Notes: 6-page abstract + poster..</small>


	<br />


	<a href="http://hcitang.org/papers/2014-chi2014wip-remote-haptics.pdf"><i class="fa fa-file-pdf-o"></i></a>


	<a href="http://hcitang.org/papers/2014-chi2014wip-remote-haptics-poster.pdf"><i class="fa fa-sticky-note-o"></i></a>



	<a href="http://dx.doi.org/10.1145/2559206.2581318"><i class="fa fa-external-link"></i></a>

</section><a class="details" href="/papers/alizadeh2014haptics/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/jones2014arttherapy"><span id="jones2014arttherapy">Brennan Jones, Sara Prins Hankinson, Kate Collie, and Anthony Tang. (2014). <span style="text-decoration: underline">Supporting Non-Verbal Visual Communication in Online Group Art Therapy</span>. In <i>CHI EA ’14: CHI ’14 Extended Abstracts on Human Factors in Computing
    Systems</i>, ACM, 1759–1764.</span>

(poster).</a><br />

	<small>Acceptance: 49% - 241/496.</small>


	<small>Notes: 6-page abstract + poster..</small>


	<br />


	<a href="http://hcitang.org/papers/2014-chi2014wip-art-therapy.pdf"><i class="fa fa-file-pdf-o"></i></a>


	<a href="http://hcitang.org/papers/2014-chi2014wip-art-therapy-poster.pdf"><i class="fa fa-sticky-note-o"></i></a>



	<a href="http://dx.doi.org/10.1145/2559206.2581302"><i class="fa fa-external-link"></i></a>

</section><a class="details" href="/papers/jones2014arttherapy/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/yarosh2013sharetablevideo"><span id="yarosh2013sharetablevideo">Svetlana Yarosh, Anthony Tang, Sanika Mokashi, and Gregory Abowd. (2013). <span style="text-decoration: underline">"Almost Touching": Parent-Child Remote Communication Using the ShareTable
    System - The Video</span>. In <i>CSCW 2013 Video Showcase Program</i>.</span>

(video).</a><br />


	<small>Notes: People’s choice award.</small>


	<br />




	<a href="https://www.youtube.com/watch?v=n8k5mYbCXhs"><i class="fa fa-film"></i></a>


</section><a class="details" href="/papers/yarosh2013sharetablevideo/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/dillman2013remotephysiotherapy"><span id="dillman2013remotephysiotherapy">Kody Dillman and Anthony Tang. (2013). <i>Towards Next-Generation Remote Physiotherapy with Videoconferencing Tools</i>. Department of Computer Science, University of Calgary.</span>

(techreport).</a><br />




	<a href="http://dspace.ucalgary.ca/jspui/bitstream/1880/49845/1/2013-1048-15.pdf"><i class="fa fa-file-pdf-o"></i></a>


	<a href="http://hdl.handle.net/1880/49845"><i class="fa fa-sticky-note-o"></i></a>



</section><a class="details" href="/papers/dillman2013remotephysiotherapy/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/ledo2013onespace"><span id="ledo2013onespace">David Ledo, Bon Adriel Aseniero, Saul Greenberg, Sebastian Boring, and Anthony Tang. (2013). <span style="text-decoration: underline">OneSpace: shared depth-corrected video interaction</span>. In <i>CHI EA ’13: CHI ’13 Extended Abstracts on Human Factors in Computing
    Systems</i>, ACM, 997–1002.</span>

(poster).</a><br />




	<a href="http://hcitang.org/papers/2013-chi2013-wip-onespace.pdf"><i class="fa fa-file-pdf-o"></i></a>




	<a href="http://doi.acm.org/10.1145/2468356.2468534"><i class="fa fa-external-link"></i></a>

</section><a class="details" href="/papers/ledo2013onespace/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/genest2013kinectarms"><span id="genest2013kinectarms">Aaron M. Genest, Carl Gutwin, Anthony Tang, Michael Kalyn, and Zenja Ivkovic. (2013). <span style="text-decoration: underline">KinectArms: a toolkit for capturing and displaying arm embodiments in
    distributed tabletop groupware</span>. In <i>CSCW ’13: Proceedings of the 2013 conference on Computer supported
    cooperative work</i>, ACM, 157–166.</span>

(conference).</a><br />

	<small>Acceptance: 35.5% - 139/390.</small>



	<br />


	<a href="http://hcitang.org/papers/2013-cscw2013-kinectarms.pdf"><i class="fa fa-file-pdf-o"></i></a>



	<a href="http://hcitang.org/papers/2013-cscw2013-kinectarms.m4v"><i class="fa fa-film"></i></a>


	<a href="http://doi.acm.org/10.1145/2441776.2441796"><i class="fa fa-external-link"></i></a>

</section><a class="details" href="/papers/genest2013kinectarms/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/yarosh2013almost"><span id="yarosh2013almost">Svetlana Yarosh, Anthony Tang, Sanika Mokashi, and Gregory D. Abowd. (2013). <span style="text-decoration: underline">"Almost touching": parent-child remote communication using the sharetable
    system</span>. In <i>CSCW ’13: Proceedings of the 2013 conference on Computer supported
    cooperative work</i>, ACM, 181–192.</span>

(conference).</a><br />

	<small>Acceptance: 35.5% - 139/390.</small>



	<br />


	<a href="http://hcitang.org/papers/2013-cscw2013-almost-touching.pdf"><i class="fa fa-file-pdf-o"></i></a>



	<a href="http://hcitang.org/papers/2013-cscw2013-almost-touching.m4v"><i class="fa fa-film"></i></a>


	<a href="http://doi.acm.org/10.1145/2441776.2441798"><i class="fa fa-external-link"></i></a>

</section><a class="details" href="/papers/yarosh2013almost/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/ledo2013onespaceworkshop"><span id="ledo2013onespaceworkshop">David Ledo, Bon Adriel Aseniero, Sebastian Boring, Saul Greenberg, and Anthony Tang. (2013). <span style="text-decoration: underline">OneSpace: Bringing Depth to Remote Interactions</span>. In <i>Future of Personal Video Communications: Beyond Talking Heads - Workshop
    at CHI 2013</i>.</span>

	(Oduor, Erick and Neustaedter, Carman and Venolia, Gina and Judge, Tejinder, Eds.)

(workshop).</a><br />




	<a href="http://hcitang.org/papers/2013-chi2013workshop-onespace.pdf"><i class="fa fa-file-pdf-o"></i></a>




</section><a class="details" href="/papers/ledo2013onespaceworkshop/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/ledo2012onespace"><span id="ledo2012onespace">David Ledo, Bon Adriel Aseniero, Sebastian Boring, and Anthony Tang. (2012). <i>OneSpace: Shared Depth-Corrected Video Interaction</i>. Department of Computer Science, University of Calgary, Department of Computer Science, University of Calgary, Calgary, Alberta,
    Canada T2N 1N4.</span>

(techreport).</a><br />




	<a href="http://hcitang.org/papers/2012-tr-onespace-2012-1033-16.pdf"><i class="fa fa-file-pdf-o"></i></a>




</section><a class="details" href="/papers/ledo2012onespace/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/tang2010expressiveness"><span id="tang2010expressiveness">Anthony Tang, Aaron Genest, Garth Shoemaker, Carl Gutwin, Sid Fels, and Kellogg S. Booth. (2010). <span style="text-decoration: underline">Enhancing Expressiveness in Reference Space</span>. In <i>New Frontiers in Telepresence - CSCW 2010 Workshop</i>.</span>

	(Venolia, Gina and Inkpen, Kori and Olson, Judith and Nguyen, David, Eds.)

(workshop).</a><br />




	<a href="http://hcitang.org/papers/2010-cscw2010-workshop-expressiveness.pdf"><i class="fa fa-file-pdf-o"></i></a>


	<a href="http://research.microsoft.com/en-us/events/nft2010/"><i class="fa fa-sticky-note-o"></i></a>



</section><a class="details" href="/papers/tang2010expressiveness/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/tang2010threes"><span id="tang2010threes">Anthony Tang, Michel Pahud, Kori Inkpen, Hrvoje Benko, John C. Tang, and Bill Buxton. (2010). <span style="text-decoration: underline">Three’s company: understanding communication channels in three-way distributed
    collaboration</span>. In <i>CSCW ’10: Proceedings of the 2010 ACM conference on Computer supported
    cooperative work</i>, ACM, 271–280.</span>

(conference).</a><br />


	<small>Notes: Best Paper Nominee (top 5% of submissions).</small>


	<br />


	<a href="http://hcitang.org/papers/2010-cscw2010-three’s-company.pdf"><i class="fa fa-file-pdf-o"></i></a>




	<a href="http://doi.acm.org/10.1145/1718918.1718969"><i class="fa fa-external-link"></i></a>

</section><a class="details" href="/papers/tang2010threes/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/tang2007videoarms"><span id="tang2007videoarms">Anthony Tang, Carman Neustaedter, and Saul Greenberg. (2007). <span style="text-decoration: underline">Videoarms: embodiments for mixed presence groupware</span>. In <i>People and Computers XX—Engage</i>, Springer London, 85–102.</span>

(conference).</a><br />




	<a href="http://hcitang.org/papers/2006-hci2006-videoarms-embodiments-in-mpg.pdf"><i class="fa fa-file-pdf-o"></i></a>




</section><a class="details" href="/papers/tang2007videoarms/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/tang2005awarenessmpg"><span id="tang2005awarenessmpg">Anthony Tang and Saul Greenberg. (2005). <span style="text-decoration: underline">Supporting Awareness in Mixed Presence Groupware</span>. In <i>Awareness Systems: Known Results, Theory, Concepts and Future Challenges
    - Workshop at CHI 2005</i>.</span>

	(Markopoulos, Paulos and Ruyter, Boris De and Mackay, Wendy, Eds.)

(workshop).</a><br />




	<a href="http://hcitang.org/papers/2005-chi2005workshop-awareness-in-mpg.pdf"><i class="fa fa-file-pdf-o"></i></a>


	<a href="http://www.awareness-research.org/WS_programme.html"><i class="fa fa-sticky-note-o"></i></a>



</section><a class="details" href="/papers/tang2005awarenessmpg/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/tang2005understanding"><span id="tang2005understanding">Anthony Tang, Michael Boyle, and Saul Greenberg. (2005). <span style="text-decoration: underline">Understanding and mitigating display and presence disparity in mixed presence
    groupware</span>. <i>Journal of research and practice in information technology</i> 37, 2: <span style="text-decoration: none">193–210</span>.</span>

(journal).</a><br />


	<small>Notes: Invited article.</small>


	<br />


	<a href="http://hcitang.org/papers/2005-jrpit-tang-display-and-presence-disparity.pdf"><i class="fa fa-file-pdf-o"></i></a>




</section><a class="details" href="/papers/tang2005understanding/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/tang2004videoarms"><span id="tang2004videoarms">Anthony Tang, Carman Neustaedter, and Saul Greenberg. (2004). <span style="text-decoration: underline">VideoArms: supporting remote embodiment in groupware</span>. In <i>Video Proceedings of CSCW 2004</i>.</span>

(video).</a><br />




	<a href="http://hcitang.org/papers/2004-cscw2004-videoarms-video.pdf"><i class="fa fa-file-pdf-o"></i></a>



	<a href="http://hcitang.org/papers/2004-cscw2004-videoarms-video.wmv"><i class="fa fa-film"></i></a>


</section><a class="details" href="/papers/tang2004videoarms/"><!-- --></a></li></ol>



							</article>
					</div>
				</div>
			</div>
		</div>
	</section>			

		<!-- Footer -->
 			<div id="footer">
				<!-- Copyright -->
					<div class="copyright">
					    <script type="text/javascript">
					    // from http://grouplab.cpsc.ucalgary.ca/
					    function hideshow(el){
						    if (!document.getElementById) return;
						    if (el.style.visibility=="visible") {
						    	el.style.visibility="hidden"
						    }
						    else {
						    	el.style.visibility="visible"
						    }
						}
					    </script>
						<ul class="menu">
							<!--
							<li><a href="https://www.google.ca/maps/place/Math+Science,+Calgary,+AB+T2N+4V8/@51.0799635,-114.1300982,17z/data=!3m1!4b1!4m2!3m1!1s0x53716f0c07993c17:0xb8f1352e9e5dfa06?hl=en"><i class="icon fa-map-marker"></i> 2500 University Drive NW, Calgary, AB T2N 1N4</a> (<a href="/directions">Directions</a>)</li><li><a href="tel:403-210-6912"><i class="icon fa-phone"></i> 403-210-6912</a></li>
							-->
							<li><a rel="nofollow" href="javascript:hideshow(document.getElementById('colophon'))">Colophon</a></li>
						</ul>
						<section id="colophon" visibility="hidden" style="visibility: hidden;">
							<ul class="menu">
								<li>Design: <a href="http://html5up.net">HTML5 UP</a></li><li>Images: <a href="http://unsplash.com/">unsplash.com</a></li><li>Icons: <a href="https://fortawesome.github.io/Font-Awesome/">font awesome</a></li><li>Bibliography: <a href="https://github.com/inukshuk/jekyll-scholar">jekyll-scholar</a></li>
							</ul>
						</section>
					</div>

			</div>

	</body>
</html>