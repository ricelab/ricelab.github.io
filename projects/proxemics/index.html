<!DOCTYPE HTML>
<!--
	Arcana by HTML5 UP - html5up.net 
-->
<html>
	<head>
		<title>Proxemic Interaction Design</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<!--[if lte IE 8]><script src="/assets/css/ie/html5shiv.js"></script><![endif]-->
		<script src="/assets/js/jquery.min.js"></script>
		<script src="/assets/js/jquery.dropotron.min.js"></script>
		<script src="/assets/js/skel.min.js"></script>
		<script src="/assets/js/skel-layers.min.js"></script>
		<script src="/assets/js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="/assets/css/skel.css" />
			<link rel="stylesheet" href="/assets/css/style.css" />
			<link rel="stylesheet" href="/assets/css/style-wide.css" />
		</noscript>
		<!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie/v8.css" /><![endif]-->
		<link rel="shortcut icon" href="/assets/images/favicon.png">
		
	</head>
	<body>

		<!-- Header -->
			<div id="header">
						
				<!-- Logo -->
					<h1><a href="/index.html" id="logo">RICELab <em style="font-size: 9pt;color: #cbcbcb" class="only-large">Rethinking Interaction Collaboration and Engagement</em></a></h1>
				
				<!-- Nav -->
					<nav id="nav">
						<ul>
							
							<li ><a href="/index.html">Home</a></li>
							<li ><a href="/about-us">About Us</a></li>
							<li ><a href="/people">People</a></li>
							<li class="current"><a href="/projects">Projects</a></li>
							<li ><a href="/papers">Publications</a></li>
							<li ><a href="/blog">Blog</a></li>
							<li ><a href="/join-us">Join Us</a></li>
							<li ><a href="/internal">Internal</a></li>
						</ul>
					</nav>
			</div>
<style>
#citation a {
  color: black;
  border-bottom: none;
}
#citation {
  margin-bottom: 1em;
}
</style>

<!-- Main -->
	<section class="wrapper style1">
		<div class="container">
			<div class="row double">
				<div class="4u">
					<div id="sidebar">

	<!-- Sidebar -->

		<section>
			<h3>Current Projects</h3>
			<ul>
			  
			    
			      <li><a href="/projects/hai-collaboration/">Human-AI Collaboration</a></li>
			    
			  
			    
			      <li><a href="/projects/proxemics/">Proxemic Interaction Design</a></li>
			    
			  
			    
			      <li><a href="/projects/haptics/">Haptics in VR</a></li>
			    
			  
			    
			      <li><a href="/projects/games/">Games and Leisure</a></li>
			    
			  
			    
			      <li><a href="/projects/efashion/">Electronic Fashion</a></li>
			    
			  
			    
			      <li><a href="/projects/360video/">360 Video Interaction</a></li>
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			</ul>

			<h3>Past Projects</h3>
			<ul>
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			  
			    
			      <li><a href="/projects/teaching-technologies/">Technologies for Teaching</a></li>
			    
			  
			    
			      <li><a href="/projects/social-watching-of-sports/">Social Watching of Sports</a></li>
			    
			  
			    
			      <li><a href="/projects/slit-tear-video/">Slit-Tear Video Exploration</a></li>
			    
			  
			    
			      <li><a href="/projects/remote-embodiment/">Remote Embodiment for Shared Activity</a></li>
			    
			  
			    
			      <li><a href="/projects/personal-informatics/">Personal Informatics and Analytics</a></li>
			    
			  
			    
			      <li><a href="/projects/physiotherapy/">Physiotherapy for the Future</a></li>
			    
			  
			    
			      <li><a href="/projects/pervasive-games/">Pervasive Games and Citizen Science</a></li>
			    
			  
			    
			      <li><a href="/projects/mobile-video-conferencing/">Mobile Video Conferencing</a></li>
			    
			  
			    
			      <li><a href="/projects/mobile-device-interaction/">Interaction Techniques for Mobile Devices</a></li>
			    
			  
			    
			      <li><a href="/projects/mixed-reality-workrooms/">Mixed Reality Workrooms</a></li>
			    
			  
			    
			      <li><a href="/projects/collaborative-visual-analytics/">Collaborative Visual Analytics</a></li>
			    
			  
			    
			      <li><a href="/projects/collaborative-ar/">Mixed Reality for Collaboration</a></li>
			    
			  
			    
			      <li><a href="/projects/multi-surface-environments/">Digital Workrooms of the Future</a></li>
			    
			  
			</ul>
		</section>
</div>
				</div>
				<div class="8u skel-cell-important">
					<div id="content">

						<!-- Content -->
					
							<article>
								<header>
									<h2>Proxemic Interaction Design</h2>
									<p>How position, orientation and identity enable new forms of interaction</p>
								</header>
								
								<!-- 160x144 -->

<p>Proxemic interaction design explores how systems can use an understanding of people’s relative position, orientation and identity with one another and objects can be used to support rich interaction techniques. For example, we can design rooms that understand to turn on the lights when someone enters, and to turn them off when people leave. Similarly, we can design interactive displays to respond appropriately when someone is looking at them from a distance or up close. This is useful since we use proxemics to mediate our interactions with other people in everyday life – for instance, by moving physically closer to people we want to interact with, and by turning away from people we don’t. Proxemic interaction design explores how these basic cues can be used to improve interaction with computing technology.</p>

<p>In <a class="citation" href="#kudo2021balancing">(Kudo, Tang, Fujita, Endo, Takashima, &amp; Kitamura, 2021)</a>, we explored how VR headsets and reveal bystanders who may be potential interaction partners based on their proximity and orientation to the VR headset user. This is important when we consider that people wearing headsets are completely cut off from the world.</p>

<p>We can also use proxemics to mediate how we interact with robots <a class="citation" href="#mahadevan2021hri">(Mahadevan, Sousa, Tang, &amp; Grossman, 2021)</a>. We have found that when robots can understand how people are using space, they can more straightforwardly anticipate how human collaborators will work. This smooths collaborative activity between humans and robots.</p>

<h2 id="publications">Publications</h2>

<ol class="bibliography"><li><section id="citation">
    <a href="/papers/mahadevan2021hri"><span id="mahadevan2021hri">Karthik Mahadevan, Mauricio Sousa, Anthony Tang, and Tovi Grossman. (2021). <span style="text-decoration: underline">"Grip-that-there": An Investigation of Explicit and Implicit Task Allocation Techniques for Human-Robot Collaboration</span>. In <i>CHI 2021: Proceedings of the 2021 SIGCHI Conference on Human Factors in Computing Systems</i>.</span>

(conference).</a><br />

	<small>Acceptance: 26.3% - 749/2844.</small>


	<small>Notes: Best Paper Nominee (top 5% of submissions).</small>


	<br />


	<a href="http://hcitang.org/papers/2021-chi2021-mahadevan-grip-that-there.pdf"><i class="fa fa-file-pdf-o"></i></a>


	<a href="https://www.youtube.com/watch?v=Fvn_qjWJqwk"><i class="fa fa-sticky-note-o"></i></a>


	<a href="http://hcitang.org/papers/2021-chi2021-mahadevan-grip-that-there.mp4"><i class="fa fa-film"></i></a>


</section><a class="details" href="/papers/mahadevan2021hri/"><!-- --></a></li>
<li><section id="citation">
    <a href="/papers/kudo2021balancing"><span id="kudo2021balancing">Yoshiki Kudo, Anthony Tang, Kazuyuki Fujita, Isamu Endo, Kazuki Takashima, and Yoshifumi Kitamura. (2021). <span style="text-decoration: underline">Towards Balancing VR Immersion and Bystander Awareness</span>. <i>Proceedings of the ACM on Human-Computer Interaction (PACMHCI)</i> 5, ISS, Article 484.</span>

(journal).</a><br />


	<small>Notes: Best Paper award.</small>


	<br />


	<a href="http://hcitang.org/papers/2021-pacmiss-balance-immersion-awareness.pdf"><i class="fa fa-file-pdf-o"></i></a>



	<a href="http://hcitang.org/papers/2021-pacmiss-balance-immersion-awareness.mp4"><i class="fa fa-film"></i></a>


	<a href="https://doi.org/10.1145/3486950"><i class="fa fa-external-link"></i></a>

</section><a class="details" href="/papers/kudo2021balancing/"><!-- --></a></li></ol>



							</article>
					</div>
				</div>
			</div>
		</div>
	</section>			

		<!-- Footer -->
 			<div id="footer">
				<!-- Copyright -->
					<div class="copyright">
					    <script type="text/javascript">
					    // from http://grouplab.cpsc.ucalgary.ca/
					    function hideshow(el){
						    if (!document.getElementById) return;
						    if (el.style.visibility=="visible") {
						    	el.style.visibility="hidden"
						    }
						    else {
						    	el.style.visibility="visible"
						    }
						}
					    </script>
						<ul class="menu">
							<!--
							<li><a href="https://www.google.ca/maps/place/Math+Science,+Calgary,+AB+T2N+4V8/@51.0799635,-114.1300982,17z/data=!3m1!4b1!4m2!3m1!1s0x53716f0c07993c17:0xb8f1352e9e5dfa06?hl=en"><i class="icon fa-map-marker"></i> 2500 University Drive NW, Calgary, AB T2N 1N4</a> (<a href="/directions">Directions</a>)</li><li><a href="tel:403-210-6912"><i class="icon fa-phone"></i> 403-210-6912</a></li>
							-->
							<li><a rel="nofollow" href="javascript:hideshow(document.getElementById('colophon'))">Colophon</a></li>
						</ul>
						<section id="colophon" visibility="hidden" style="visibility: hidden;">
							<ul class="menu">
								<li>Design: <a href="http://html5up.net">HTML5 UP</a></li><li>Images: <a href="http://unsplash.com/">unsplash.com</a></li><li>Icons: <a href="https://fortawesome.github.io/Font-Awesome/">font awesome</a></li><li>Bibliography: <a href="https://github.com/inukshuk/jekyll-scholar">jekyll-scholar</a></li>
							</ul>
						</section>
					</div>

			</div>

	</body>
</html>